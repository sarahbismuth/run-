{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime\n",
    "from selenium import webdriver as wd\n",
    "import urllib.parse\n",
    "from urllib.request import Request, urlopen\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import csv\n",
    "from credentials import credentials\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping text data - contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-28-15b7a9045782>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-15b7a9045782>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    with open(file_name, \"w\") as file:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "## def write_to_csv_file(data, file_name): \n",
    "    with open(file_name, \"w\") as file: \n",
    "        csvwriter = csv.writer(file) # creates the csv writer object \n",
    "        \n",
    "        csvwriter.writerow(['profile_name', 'caption', 'tags']) # writing the data\n",
    "        csvwriter.writerows(data) # writing the data rows\n",
    "\n",
    "raw_add = open('/Users/sarahbismuth/Downloads/huge_if.csv','r')\n",
    "csv_data = csv.reader(raw_add)\n",
    "#new_add = open('/Users/sarahbismuth/Downloads/influencers_new2.csv','w',newline='')\n",
    "\n",
    "# pop up the website and then login to IG\n",
    "chrome_driver = '/Users/sarahbismuth/Downloads/chromedriver'\n",
    "driver = wd.Chrome(chrome_driver)\n",
    "driver.get('https://www.instagram.com/accounts/login/?next=%2Flogin%2F&source=desktop_nav')\n",
    "sleep(2)\n",
    "username_input = driver.find_element_by_name('username')\n",
    "password_input = driver.find_element_by_name('password')\n",
    "username_input.send_keys('bissarah') # use testing account\n",
    "password_input.send_keys('Levny1998')\n",
    "login_button = driver.find_element_by_xpath(\"//button[@type='submit']\")\n",
    "login_button.click()\n",
    "sleep(5)\n",
    "\n",
    "# get influencer's accounts name only\n",
    "huge_if_accounts = []\n",
    "for i in csv_data:\n",
    "    code = i[1] # getting the user name\n",
    "    huge_if_accounts.append(code)\n",
    "    \n",
    "huge_if_accounts = huge_if_accounts[901:1010]  #huge_if_accounts[2] \n",
    "print(huge_if_accounts)\n",
    "#huge_if_accounts\n",
    "    \n",
    "    \n",
    "# showing influencer's webpage\n",
    "# showing influencer's webpage\n",
    "# showing influencer's webpage\n",
    "output_data = []\n",
    "for profile_name in huge_if_accounts:\n",
    "    print(profile_name)\n",
    "    driver.get('https://www.instagram.com/{0}/?hl=en'.format(profile_name))\n",
    "    sleep(5)\n",
    "    # while statement(?)\n",
    "    # Scraping their first post\n",
    "    #post_article = driver.find_element_by_tag_name('article')\n",
    "    #posts = post_article.find_elements_by_class_name('v1Nh3')\n",
    "    # going 2 divs down to get the rows \n",
    "    #content = driver.find_elements_by_css_selector(\"article div > div > div\") # first row of data \n",
    "\n",
    "    html = driver.page_source\n",
    "    # print(\"All the the html\", html)\n",
    "    soup = bs(html, 'html.parser')\n",
    "\n",
    "    contents = soup.select('article div div a')\n",
    "    #print(f'There are links in this page. {contents}')\n",
    "    #print(\"Total number of links in the article\")\n",
    "    #print(len(contents))\n",
    "    # iterates through all the comments and captions for this one user \n",
    "    for anchor in contents: \n",
    "        url = 'https://www.instagram.com{}'.format(anchor.get(\"href\"))\n",
    "        driver.get(url)\n",
    "        print(url)\n",
    "        html_content = driver.page_source\n",
    "        soup_post = bs(html_content, 'html.parser')\n",
    "        comment = soup_post.select(\"#react-root > section > main > div > div > article > div > div > ul > div > li > div > div > div > span\")\n",
    "        #print(\"This the comment\")\n",
    "        caption_tag = []\n",
    "        for c in comment: \n",
    "            text = c.text\n",
    "            #print(\"This is text\")\n",
    "            #print(text)\n",
    "            if text == None or text == \"\":\n",
    "                continue \n",
    "\n",
    "            index_hash_tag = text.find(\"#\")\n",
    "            res = []\n",
    "            if index_hash_tag == -1:\n",
    "                res.append(profile_name)\n",
    "                res.append(text)\n",
    "                res.append(\"\")\n",
    "            else:\n",
    "                res.append(profile_name)\n",
    "                res.append(text[:index_hash_tag])\n",
    "                res.append(text[index_hash_tag:])\n",
    "\n",
    "            caption_tag.append(res)\n",
    "            break\n",
    "        output_data.extend(caption_tag) # add list to the end of the output list for export into file \n",
    "        \n",
    "        #print(comment)\n",
    "        sleep(2)\n",
    "\n",
    "write_to_csv_file(output_data, 'influencers_dOOO.csv')\n",
    "    \n",
    "    \n",
    "# target is contained like this by css selector: \n",
    "#body > div._2dDPU.RnrQH.CkGkG > div.zZYga \n",
    "#> div > article > div.eo2As > div.EtaWk > ul > div > li > div > div > div.C4VMK > span\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(posts)\n",
    "print(len(posts))\n",
    "links = []\n",
    "for post in posts:\n",
    "    link = post.find_element_by_tag_name('a').get_attribute('href')\n",
    "    links.append(link)\n",
    "\n",
    "\n",
    "for link in links:\n",
    "    driver.get(link)\n",
    "    sleep(2)\n",
    " # caption_box = driver.find_element_by_class_name('C4VMK')\n",
    "caption_box = driver.find_element_by_xpath(\"//h2[contains(@class, '_6lAjh')]/following-sibling::span\")\n",
    "caption = caption_box.text\n",
    "words = caption.split()\n",
    "tags = []\n",
    "for word in words.copy():\n",
    "    if len(word) > 0:\n",
    "         if word[0] == '#':\n",
    "            tags.append(word)\n",
    "            words.remove(word)\n",
    "caption = ' '.join(words)\n",
    "\n",
    "# creating a new file\n",
    "wr = csv.writer(new_add)\n",
    "wr.writerow([i,posts,caption,tags])\n",
    "\n",
    "\n",
    "new_add.close()\n",
    "raw_add.close()\n",
    "\"\"\"\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e085526377ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mraw_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/sarahbismuth/Downloads/huge_if.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcsv_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#new_add = open('/Users/sarahbismuth/Downloads/influencers_new2.csv','w',newline='')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "def write_to_csv_file(data, file_name): \n",
    "    with open(file_name, \"w\") as file: \n",
    "        csvwriter = csv.writer(file) # creates the csv writer object \n",
    "        \n",
    "        csvwriter.writerow(['profile_name', 'caption', 'tags']) # writing the data\n",
    "        csvwriter.writerows(data) # writing the data rows\n",
    "\n",
    "raw_add = open('/Users/sarahbismuth/Downloads/huge_if.csv','r')\n",
    "csv_data = csv.reader(raw_add)\n",
    "#new_add = open('/Users/sarahbismuth/Downloads/influencers_new2.csv','w',newline='')\n",
    "\n",
    "# pop up the website and then login to IG\n",
    "chrome_driver = '/Users/sarahbismuth/Downloads/chromedriver'\n",
    "driver = wd.Chrome(chrome_driver)\n",
    "driver.get('https://www.instagram.com/accounts/login/?next=%2Flogin%2F&source=desktop_nav')\n",
    "sleep(2)\n",
    "username_input = driver.find_element_by_name('username')\n",
    "password_input = driver.find_element_by_name('password')\n",
    "username_input.send_keys('bissarah') # use testing account\n",
    "password_input.send_keys('Levny1998')\n",
    "login_button = driver.find_element_by_xpath(\"//button[@type='submit']\")\n",
    "login_button.click()\n",
    "sleep(5)\n",
    "\n",
    "# get influencer's accounts name only\n",
    "huge_if_accounts = []\n",
    "for i in csv_data:\n",
    "    code = i[1] # getting the user name\n",
    "    huge_if_accounts.append(code)\n",
    "    \n",
    "huge_if_accounts = huge_if_accounts[901:1010]  #huge_if_accounts[2] \n",
    "print(huge_if_accounts)\n",
    "#huge_if_accounts\n",
    "    \n",
    "    \n",
    "# showing influencer's webpage\n",
    "# showing influencer's webpage\n",
    "# showing influencer's webpage\n",
    "output_data = []\n",
    "for profile_name in huge_if_accounts:\n",
    "    print(profile_name)\n",
    "    driver.get('https://www.instagram.com/{0}/?hl=en'.format(profile_name))\n",
    "    sleep(5)\n",
    "    # while statement(?)\n",
    "    # Scraping their first post\n",
    "    #post_article = driver.find_element_by_tag_name('article')\n",
    "    #posts = post_article.find_elements_by_class_name('v1Nh3')\n",
    "    # going 2 divs down to get the rows \n",
    "    #content = driver.find_elements_by_css_selector(\"article div > div > div\") # first row of data \n",
    "\n",
    "    html = driver.page_source\n",
    "    # print(\"All the the html\", html)\n",
    "    soup = bs(html, 'html.parser')\n",
    "\n",
    "    contents = soup.select('article div div a')\n",
    "    #print(f'There are links in this page. {contents}')\n",
    "    #print(\"Total number of links in the article\")\n",
    "    #print(len(contents))\n",
    "    # iterates through all the comments and captions for this one user \n",
    "    for anchor in contents: \n",
    "        url = 'https://www.instagram.com{}'.format(anchor.get(\"href\"))\n",
    "        driver.get(url)\n",
    "        print(url)\n",
    "        html_content = driver.page_source\n",
    "        soup_post = bs(html_content, 'html.parser')\n",
    "        comment = soup_post.select(\"#react-root > section > main > div > div > article > div > div > ul > div > li > div > div > div > span\")\n",
    "        #print(\"This the comment\")\n",
    "        caption_tag = []\n",
    "        for c in comment: \n",
    "            text = c.text\n",
    "            #print(\"This is text\")\n",
    "            #print(text)\n",
    "            if text == None or text == \"\":\n",
    "                continue \n",
    "\n",
    "            index_hash_tag = text.find(\"#\")\n",
    "            res = []\n",
    "            if index_hash_tag == -1:\n",
    "                res.append(profile_name)\n",
    "                res.append(text)\n",
    "                res.append(\"\")\n",
    "            else:\n",
    "                res.append(profile_name)\n",
    "                res.append(text[:index_hash_tag])\n",
    "                res.append(text[index_hash_tag:])\n",
    "\n",
    "            caption_tag.append(res)\n",
    "            break\n",
    "        output_data.extend(caption_tag) # add list to the end of the output list for export into file \n",
    "        \n",
    "        #print(comment)\n",
    "        sleep(2)\n",
    "\n",
    "write_to_csv_file(output_data, 'influencers_datapy_1PART22_3.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
